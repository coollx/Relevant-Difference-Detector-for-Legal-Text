{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.facecolor'] = 'white'\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一. Data inspection: 检查distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>similarity</th>\n",
       "      <th>category3</th>\n",
       "      <th>doc1</th>\n",
       "      <th>doc2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>STYLYSTIC</td>\n",
       "      <td>dispute between the contracting parties concer...</td>\n",
       "      <td>disputes between contracting parties regarding...</td>\n",
       "      <td>0.967505</td>\n",
       "      <td>['State-to-state Arbitration']</td>\n",
       "      <td>t1996-66-chile-greece-bit-1996</td>\n",
       "      <td>t2000-13-bangladesh-switzerland-bit-2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IRRELEVANT</td>\n",
       "      <td>said period shall start on the day on which th...</td>\n",
       "      <td>royalties and other payments deriving from rig...</td>\n",
       "      <td>0.841040</td>\n",
       "      <td>[]</td>\n",
       "      <td>t1996-66-chile-greece-bit-1996</td>\n",
       "      <td>t2000-13-bangladesh-switzerland-bit-2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>STYLYSTIC</td>\n",
       "      <td>between the contracting parties concerning the...</td>\n",
       "      <td>any dispute between the contracting parties c...</td>\n",
       "      <td>0.965822</td>\n",
       "      <td>['State-to-state Arbitration']</td>\n",
       "      <td>t1994-147-kazakhstan-ukraine-bit-1994</td>\n",
       "      <td>t2009-107-slovakia-syrian-arab-republic-bit-2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>STYLYSTIC</td>\n",
       "      <td>provisions of paragraph 1 of this article shal...</td>\n",
       "      <td>where a contracting party expropriates the as...</td>\n",
       "      <td>0.965317</td>\n",
       "      <td>['Expropriation Conditions']</td>\n",
       "      <td>t1994-147-kazakhstan-ukraine-bit-1994</td>\n",
       "      <td>t2009-107-slovakia-syrian-arab-republic-bit-2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>STYLYSTIC</td>\n",
       "      <td>respect of investment made prior to the date o...</td>\n",
       "      <td>with regard to investments made before the not...</td>\n",
       "      <td>0.971554</td>\n",
       "      <td>['Termination']</td>\n",
       "      <td>t2004-38-china-finland-bit-2004</td>\n",
       "      <td>t2004-43-congo-democratic-republic-of-the-jord...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        label                                          sentence1  \\\n",
       "0   STYLYSTIC  dispute between the contracting parties concer...   \n",
       "1  IRRELEVANT  said period shall start on the day on which th...   \n",
       "2   STYLYSTIC  between the contracting parties concerning the...   \n",
       "3   STYLYSTIC  provisions of paragraph 1 of this article shal...   \n",
       "4   STYLYSTIC  respect of investment made prior to the date o...   \n",
       "\n",
       "                                           sentence2  similarity  \\\n",
       "0  disputes between contracting parties regarding...    0.967505   \n",
       "1  royalties and other payments deriving from rig...    0.841040   \n",
       "2   any dispute between the contracting parties c...    0.965822   \n",
       "3   where a contracting party expropriates the as...    0.965317   \n",
       "4  with regard to investments made before the not...    0.971554   \n",
       "\n",
       "                        category3                                   doc1  \\\n",
       "0  ['State-to-state Arbitration']         t1996-66-chile-greece-bit-1996   \n",
       "1                              []         t1996-66-chile-greece-bit-1996   \n",
       "2  ['State-to-state Arbitration']  t1994-147-kazakhstan-ukraine-bit-1994   \n",
       "3    ['Expropriation Conditions']  t1994-147-kazakhstan-ukraine-bit-1994   \n",
       "4                 ['Termination']        t2004-38-china-finland-bit-2004   \n",
       "\n",
       "                                                doc2  \n",
       "0           t2000-13-bangladesh-switzerland-bit-2000  \n",
       "1           t2000-13-bangladesh-switzerland-bit-2000  \n",
       "2   t2009-107-slovakia-syrian-arab-republic-bit-2009  \n",
       "3   t2009-107-slovakia-syrian-arab-republic-bit-2009  \n",
       "4  t2004-43-congo-democratic-republic-of-the-jord...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datapath = 'generated_data/similar_sentences.xlsx'\n",
    "df = pd.read_excel(datapath)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='label'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.groupby(['label']).size().plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 二. bert tokenizer demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "from transformers import RobertaTokenizer\n",
    "#tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "example_text = 'I will watch Memento tonight'\n",
    "bert_input = tokenizer(example_text, example_text ,padding='max_length', max_length = 20, \n",
    "                       truncation=True, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  1045,  2097,  3422,  2033, 23065,  3892,   102,  1045,  2097,\n",
       "          3422,  2033, 23065,  3892,   102,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]])}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  101,  1045,  2097,  3422,  2033, 23065,  3892,   102,  1045,  2097,\n",
      "          3422,  2033, 23065,  3892,   102,     0,     0,     0,     0,     0]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "print(bert_input['input_ids'])\n",
    "print(bert_input['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] i will watch memento tonight [SEP] i will watch memento tonight [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_text = tokenizer.decode(bert_input.input_ids[0])\n",
    "example_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 三. Data set: 数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "labels = {'RELEVANT': 0, 'STYLYSTIC': 1, 'IRRELEVANT': 2}\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, df):\n",
    "\n",
    "        self.labels = [labels[label] for label in df['label']]\n",
    "        self.texts = [tokenizer(s1, s2, \n",
    "                               padding='max_length', max_length = 512, truncation=True,\n",
    "                                return_tensors=\"pt\") for s1, s2 in zip(df['sentence1'], df['sentence2'])]\n",
    "\n",
    "    def classes(self):\n",
    "        return self.labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def get_batch_labels(self, idx):\n",
    "        # Fetch a batch of labels\n",
    "        return np.array(self.labels[idx])\n",
    "\n",
    "    def get_batch_texts(self, idx):\n",
    "        # Fetch a batch of inputs\n",
    "        return self.texts[idx]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        batch_texts = self.get_batch_texts(idx)\n",
    "        batch_y = self.get_batch_labels(idx)\n",
    "\n",
    "        return batch_texts, batch_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train set splt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5032 629 629\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "df_train, df_val, df_test = np.split(df.sample(frac=1, random_state=42), \n",
    "                                     [int(.8*len(df)), int(.9*len(df))])\n",
    "\n",
    "print(len(df_train),len(df_val), len(df_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 四. Model: 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from transformers import BertModel\n",
    "\n",
    "class BertClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self, dropout=0.5):\n",
    "\n",
    "        super(BertClassifier, self).__init__()\n",
    "\n",
    "        self.bert = BertModel.from_pretrained('bert-base-cased')\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear = nn.Linear(768, 3)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, input_id, mask):\n",
    "        _, pooled_output = self.bert(input_ids= input_id, attention_mask=mask,return_dict=False)\n",
    "        dropout_output = self.dropout(pooled_output)\n",
    "        linear_output = self.linear(dropout_output)\n",
    "        final_layer = self.relu(linear_output)\n",
    "\n",
    "        return final_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see from the code above, BERT model outputs two variables:\n",
    "1. The first variable, which we named _ in the code above, contains the embedding vectors of all of the tokens in a sequence.\n",
    "2. The second variable, which we named pooled_output, contains the embedding vector of [CLS] token. For a text classification task, it is enough to use this embedding as an input for our classifier.\n",
    "\n",
    "We then pass the pooled_output variable into a linear layer with ReLU activation function. At the end of the linear layer, we have a vector of size 5, each corresponds to a category of our labels (sport, business, politics, entertainment, and tech)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 五. Training: 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|██████████| 315/315 [01:49<00:00,  2.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 1 | Train Loss:  0.051                 | Train Accuracy:  0.653                 | Val Loss:  0.041                 | Val Accuracy:  0.754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 315/315 [01:49<00:00,  2.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 2 | Train Loss:  0.031                 | Train Accuracy:  0.830                 | Val Loss:  0.029                 | Val Accuracy:  0.841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 315/315 [01:49<00:00,  2.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 3 | Train Loss:  0.023                 | Train Accuracy:  0.900                 | Val Loss:  0.023                 | Val Accuracy:  0.873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 315/315 [01:49<00:00,  2.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 4 | Train Loss:  0.016                 | Train Accuracy:  0.931                 | Val Loss:  0.017                 | Val Accuracy:  0.921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 315/315 [01:49<00:00,  2.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 5 | Train Loss:  0.012                 | Train Accuracy:  0.960                 | Val Loss:  0.013                 | Val Accuracy:  0.948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 315/315 [01:49<00:00,  2.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 6 | Train Loss:  0.009                 | Train Accuracy:  0.972                 | Val Loss:  0.010                 | Val Accuracy:  0.951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 315/315 [01:49<00:00,  2.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 7 | Train Loss:  0.007                 | Train Accuracy:  0.982                 | Val Loss:  0.009                 | Val Accuracy:  0.962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 315/315 [01:49<00:00,  2.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 8 | Train Loss:  0.005                 | Train Accuracy:  0.989                 | Val Loss:  0.008                 | Val Accuracy:  0.965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 315/315 [01:49<00:00,  2.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 9 | Train Loss:  0.004                 | Train Accuracy:  0.993                 | Val Loss:  0.007                 | Val Accuracy:  0.971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 315/315 [01:49<00:00,  2.87it/s]\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import Adam\n",
    "from tqdm import tqdm\n",
    "\n",
    "def train(model, train_data, val_data, learning_rate, epochs):\n",
    "\n",
    "    train, val = Dataset(train_data), Dataset(val_data)\n",
    "\n",
    "    train_dataloader = torch.utils.data.DataLoader(train, batch_size=16, shuffle=True)\n",
    "    val_dataloader = torch.utils.data.DataLoader(val, batch_size=16)\n",
    "\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    #use_cuda = False\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = Adam(model.parameters(), lr= learning_rate)\n",
    "\n",
    "    if use_cuda:\n",
    "\n",
    "            model = model.cuda()\n",
    "            criterion = criterion.cuda()\n",
    "\n",
    "    for epoch_num in range(epochs):\n",
    "\n",
    "            total_acc_train = 0\n",
    "            total_loss_train = 0\n",
    "\n",
    "            for train_input, train_label in tqdm(train_dataloader):\n",
    "\n",
    "                train_label = train_label.to(device)\n",
    "                mask = train_input['attention_mask'].to(device)\n",
    "                input_id = train_input['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "                output = model(input_id, mask)\n",
    "                \n",
    "                batch_loss = criterion(output, train_label.long())\n",
    "                total_loss_train += batch_loss.item()\n",
    "                \n",
    "                acc = (output.argmax(dim=1) == train_label).sum().item()\n",
    "                total_acc_train += acc\n",
    "\n",
    "                model.zero_grad()\n",
    "                batch_loss.backward()\n",
    "                optimizer.step()\n",
    "            \n",
    "            total_acc_val = 0\n",
    "            total_loss_val = 0\n",
    "\n",
    "            with torch.no_grad():\n",
    "\n",
    "                for val_input, val_label in val_dataloader:\n",
    "\n",
    "                    val_label = val_label.to(device)\n",
    "                    mask = val_input['attention_mask'].to(device)\n",
    "                    input_id = val_input['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "                    output = model(input_id, mask)\n",
    "\n",
    "                    batch_loss = criterion(output, val_label.long())\n",
    "                    total_loss_val += batch_loss.item()\n",
    "                    \n",
    "                    acc = (output.argmax(dim=1) == val_label).sum().item()\n",
    "                    total_acc_val += acc\n",
    "            \n",
    "            print(\n",
    "                f'Epochs: {epoch_num + 1} | Train Loss: {total_loss_train / len(train_data): .3f} \\\n",
    "                | Train Accuracy: {total_acc_train / len(train_data): .3f} \\\n",
    "                | Val Loss: {total_loss_val / len(val_data): .3f} \\\n",
    "                | Val Accuracy: {total_acc_val / len(val_data): .3f}')\n",
    "                  \n",
    "EPOCHS = 20\n",
    "model = BertClassifier()\n",
    "LR = 1e-6\n",
    "              \n",
    "train(model, df_train, df_val, LR, EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 六. Evaluation: 测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  0.991\n"
     ]
    }
   ],
   "source": [
    "def evaluate(model, test_data):\n",
    "\n",
    "    test = Dataset(test_data)\n",
    "\n",
    "    test_dataloader = torch.utils.data.DataLoader(test, batch_size=16)\n",
    "\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "    if use_cuda:\n",
    "        model = model.cuda()\n",
    "\n",
    "    total_acc_test = 0\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for test_input, test_label in test_dataloader:\n",
    "\n",
    "              test_label = test_label.to(device)\n",
    "              mask = test_input['attention_mask'].to(device)\n",
    "              input_id = test_input['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "              output = model(input_id, mask)\n",
    "\n",
    "              acc = (output.argmax(dim=1) == test_label).sum().item()\n",
    "              total_acc_test += acc\n",
    "    \n",
    "    print(f'Test Accuracy: {total_acc_test / len(test_data): .3f}')\n",
    "    \n",
    "evaluate(model, df_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('legal')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "06852cdbcf28824f4856c911260dff4aa3407a086ba977abbb1a931f2b398117"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import xml.etree.ElementTree as ET\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Non-derogation'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('data/category_configuration_09-08-2022_08-08-01.xlsx', sheet_name = 'article_names_matching')\n",
    "title_dict = dict(zip(df[\"Article Title\"], df[\"Category 2\"]))\n",
    "title_dict.get(\"application\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_article_text(article):\n",
    "    \n",
    "    text = \"\"\n",
    "\n",
    "    for child in article:\n",
    "        text += \" \"+child.text\n",
    "    \n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_articles: 14\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'I': 'I',\n",
       " 'II': 'II',\n",
       " 'III': 'III',\n",
       " 'IV': 'IV',\n",
       " 'V': 'V',\n",
       " 'VI': 'VI',\n",
       " 'VII': 'VII',\n",
       " 'VIII': 'VIII',\n",
       " 'IX': 'IX',\n",
       " 'X': 'X',\n",
       " 'XI': 'XI',\n",
       " 'XIII': 'XII',\n",
       " 'XIV': 'XIV'}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def article_alignment(doc1_path, doc2_path):\n",
    "\n",
    "    doc1, doc2 = ET.parse(doc1_path), ET.parse(doc2_path)\n",
    "    root1, root2 = doc1.getroot(), doc2.getroot()\n",
    "    try:\n",
    "        body1, body2 = root1[1][2], root2[1][2]\n",
    "    except:\n",
    "        return\n",
    "    num_pages = max(len(root1[1][2]), len(root2[1][2]))\n",
    "    print('num_articles:', num_pages)\n",
    "    model = SentenceTransformer('distilbert-base-nli-mean-tokens')\n",
    "    #model = AutoModelForSequenceClassification.from_pretrained(\"roberta-large-mnli\")\n",
    "    article_dict = {}\n",
    "\n",
    "    #if False:\n",
    "    if \"title\" in body1[0].attrib and \"title\" in body2[0].attrib:\n",
    "    #title included in article attri\n",
    "        for article1 in body1:\n",
    "\n",
    "            \n",
    "\n",
    "            for article2 in body2:\n",
    "\n",
    "                title1 = article1.get(\"title\")\n",
    "                title2 = article2.get(\"title\")\n",
    "\n",
    "                if title_dict.get(title1.lower()) == title_dict.get(title2.lower()):\n",
    "\n",
    "                    text1_embd = model.encode(get_article_text(article1))\n",
    "                    text2_embd = model.encode(get_article_text(article2))\n",
    "                    scores = util.cos_sim(text1_embd, text2_embd)\n",
    "\n",
    "                    if max(scores[0])>0.7:\n",
    "                        article_dict[article1.get(\"num\")] = article2.get(\"num\")\n",
    "\n",
    "    else:\n",
    "    #title not included in article attri, use sentence similarity instead\n",
    "\n",
    "        for article1 in body1:\n",
    "            \n",
    "            text1_embd = model.encode(get_article_text(article1))\n",
    "            text2_list_embd = model.encode([get_article_text(article2) for article2 in body2])\n",
    "            scores = util.cos_sim(text1_embd, text2_list_embd)\n",
    "            maxi = max(scores[0])\n",
    "            print(maxi)\n",
    "\n",
    "            if maxi > 0.7:\n",
    "\n",
    "                index = np.argmax(scores[0])\n",
    "                article_dict[article1.get(\"num\")] = body2[index].get(\"num\")\n",
    "\n",
    "\n",
    "\n",
    "    return article_dict\n",
    "\n",
    "article_alignment('data/full data/t1989-9-canada-russian-federation-bit-1989.xml', 'data/full data/t1990-14-canada-czech-republic-bit-1990.xml')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0b763bb86ee93252df19d4bd54cbe9276292bdb09ab6bdcdd7ab663e1bedab76"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
